# ğŸ¤– RAG Chatbot

A production-ready Python RAG (Retrieval-Augmented Generation) Chatbot with Streamlit UI. Chat normally or upload PDFs to have AI-powered conversations about your documents.

![Python](https://img.shields.io/badge/Python-3.10+-blue.svg)
![Streamlit](https://img.shields.io/badge/Streamlit-1.28+-red.svg)
![License](https://img.shields.io/badge/License-MIT-green.svg)

## âœ¨ Features

- **ğŸ’¬ Normal Chat Mode**: Have natural conversations with the AI
- **ğŸ“š RAG Mode**: Upload PDFs and ask questions about their content
- **ğŸ”„ Auto-Switch**: Automatically switches between normal and RAG mode
- **ğŸ’¾ Persistent Storage**: Vector embeddings are saved locally
- **âš™ï¸ Configurable**: Adjust chunk size and overlap via UI
- **âš¡ Super Fast**: Uses Groq API for lightning-fast inference (free tier available)

## ğŸ› ï¸ Tech Stack

| Component | Technology |
|-----------|------------|
| **LLM** | Groq (Llama 3.3 / Mixtral) |
| **Embeddings** | sentence-transformers (all-MiniLM-L6-v2) |
| **Vector Store** | FAISS |
| **PDF Parsing** | PyPDF2 |
| **UI** | Streamlit |
| **Orchestration** | LangChain |

## ğŸ“‹ Prerequisites

### 1. Python 3.10+

Make sure you have Python 3.10 or higher installed:

```bash
python --version
```

### 2. Groq API Key (Free)

Get your free API key from Groq Console:

1. Visit [https://console.groq.com/keys](https://console.groq.com/keys)
2. Sign in or create an account
3. Click "Create API Key"
4. Copy the key for use in the setup

## ğŸš€ Installation

### 1. Clone/Navigate to Project

```bash
cd rag_chatbot
```

### 2. Create Virtual Environment (Recommended)

```bash
# Create virtual environment
python -m venv venv

# Activate it
# Windows:
venv\Scripts\activate

# macOS/Linux:
source venv/bin/activate
```

### 3. Install Dependencies

```bash
pip install -r requirements.txt
```

### 4. Set API Key

Choose one of these methods:

**Option A: Environment Variable (Recommended)**
```bash
# Windows PowerShell:
$env:GROQ_API_KEY = "your-api-key-here"

# Windows Command Prompt:
set GROQ_API_KEY=your-api-key-here

# macOS/Linux:
export GROQ_API_KEY="your-api-key-here"
```

**Option B: Direct in config.py**
Edit `config.py` and add your key:
```python
GROQ_API_KEY = "your-api-key-here"
```

## ğŸ® Running the App

```bash
streamlit run app.py
```

The app will open in your browser at `http://localhost:8501`

## ğŸ“– How to Use

### Normal Chat Mode

1. Simply type your message in the chat input
2. Press Enter to send
3. The AI will respond naturally

### RAG Mode (Chat with PDFs)

1. **Upload PDFs**: Use the sidebar to upload one or more PDF files
2. **Configure Chunking** (optional): Adjust chunk size and overlap
3. **Process**: Click "Process PDFs" to index the documents
4. **Ask Questions**: Type questions about your documents
5. **View Sources**: Expand the "Sources" section to see where answers came from

## ğŸ“ Project Structure

```
rag_chatbot/
â”‚
â”œâ”€â”€ app.py                      # Streamlit entry point
â”œâ”€â”€ config.py                   # Configuration settings
â”œâ”€â”€ requirements.txt            # Python dependencies
â”œâ”€â”€ README.md                   # This file
â”‚
â”œâ”€â”€ loaders/
â”‚   â”œâ”€â”€ __init__.py
â”‚   â””â”€â”€ pdf_loader.py           # PDF loading & parsing
â”‚
â”œâ”€â”€ embeddings/
â”‚   â”œâ”€â”€ __init__.py
â”‚   â””â”€â”€ embedder.py             # Sentence transformer embeddings
â”‚
â”œâ”€â”€ vectorstore/
â”‚   â”œâ”€â”€ __init__.py
â”‚   â””â”€â”€ store.py                # FAISS vector storage
â”‚
â”œâ”€â”€ retriever/
â”‚   â”œâ”€â”€ __init__.py
â”‚   â””â”€â”€ retriever.py            # Document retrieval
â”‚
â”œâ”€â”€ chat/
â”‚   â”œâ”€â”€ __init__.py
â”‚   â””â”€â”€ conversation.py         # Groq chat integration
â”‚
â”œâ”€â”€ prompts/
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ chat_prompt.py          # Normal chat prompts
â”‚   â””â”€â”€ rag_prompt.py           # RAG-specific prompts
â”‚
â”œâ”€â”€ utils/
â”‚   â”œâ”€â”€ __init__.py
â”‚   â””â”€â”€ helpers.py              # Utility functions
â”‚
â””â”€â”€ data/
    â”œâ”€â”€ pdfs/                   # Uploaded PDFs (auto-created)
    â””â”€â”€ vectorstore/            # Saved embeddings (auto-created)
```

## âš™ï¸ Configuration

Edit `config.py` to customize:

```python
# Change the Groq model
GROQ_MODEL = "llama-3.3-70b-versatile"  # or "mixtral-8x7b-32768", etc.

# Adjust default chunking
DEFAULT_CHUNK_SIZE = 1000
DEFAULT_CHUNK_OVERLAP = 200

# Modify retrieval settings
TOP_K_DOCUMENTS = 4
SIMILARITY_THRESHOLD = 0.3
```

## ğŸ”§ Troubleshooting

### API Key Error

**Error**: `Groq API key not found`

**Solution**: 
- Make sure you've set the `GROQ_API_KEY` environment variable
- Or add it directly to `config.py`
- Get a free key at: https://console.groq.com/keys

### Rate Limit Error

**Error**: `Rate limit reached`

**Solution**: 
- Groq's free tier has limits on requests per minute (RPM) and tokens per minute (TPM).
- Wait a few seconds before retrying.
- Switch to a smaller model like `llama-3.1-8b-instant` in `config.py` if needed.

## ğŸ¤ Contributing

Contributions are welcome! Feel free to:

1. Fork the repository
2. Create a feature branch
3. Make your changes
4. Submit a pull request

## ğŸ™ Acknowledgments

- [Groq](https://groq.com/) for lightning-fast AI inference
- [Sentence Transformers](https://www.sbert.net/) for embeddings
- [FAISS](https://github.com/facebookresearch/faiss) for vector search
- [Streamlit](https://streamlit.io) for the UI framework
- [LangChain](https://langchain.com) for orchestration